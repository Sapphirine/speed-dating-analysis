{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/speed_dating_data.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8378 entries, 0 to 8377\n",
      "Columns: 195 entries, iid to amb5_3\n",
      "dtypes: float64(174), int64(13), object(8)\n",
      "memory usage: 12.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>...</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [iid, id, gender, idg, condtn, wave, round, position, positin1, order, partner, pid, match, int_corr, samerace, age_o, race_o, pf_o_att, pf_o_sin, pf_o_int, pf_o_fun, pf_o_amb, pf_o_sha, dec_o, attr_o, sinc_o, intel_o, fun_o, amb_o, shar_o, like_o, prob_o, met_o, age, field, field_cd, undergra, mn_sat, tuition, race, imprace, imprelig, from, zipcode, income, goal, date, go_out, career, career_c, sports, tvsports, exercise, dining, museums, art, hiking, gaming, clubbing, reading, tv, theater, movies, concerts, music, shopping, yoga, exphappy, expnum, attr1_1, sinc1_1, intel1_1, fun1_1, amb1_1, shar1_1, attr4_1, sinc4_1, intel4_1, fun4_1, amb4_1, shar4_1, attr2_1, sinc2_1, intel2_1, fun2_1, amb2_1, shar2_1, attr3_1, sinc3_1, fun3_1, intel3_1, amb3_1, attr5_1, sinc5_1, intel5_1, fun5_1, amb5_1, dec, attr, sinc, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 195 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all male records to eliminate duplicates in interaction records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.gender == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify: match iff dec & dec_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.concat([\n",
    "#     df.match,\n",
    "#     df.dec,\n",
    "#     df.dec_o\n",
    "# ], axis=1)\n",
    "\n",
    "# test_df['expected'] = test_df.apply(lambda row: row.dec&row.dec_o == row.match, axis=1)\n",
    "# assert test_df.expected.sum()==len(test_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use self evaluation or perception by others as proxy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.concat([\n",
    "#     df.iid, df.pid,\n",
    "#     df.loc[:, 'attr3_1':'amb3_1'],  # How do you think you measure up?\n",
    "#     df.loc[:, 'attr5_1':'amb5_1'],  # How do others perceive you?\n",
    "# ], axis=1)\n",
    "\n",
    "# test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too many missing values for \"How do others perceive you\" results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning / Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([\n",
    "    df.iid, df.partner, df.pid, # id of self and partner, to be removed later\n",
    "    df.gender,\n",
    "    df.age, df.age_o,\n",
    "    df.int_corr, # correlation of interests\n",
    "    df.samerace,\n",
    "    df.goal,\n",
    "    df.date,\n",
    "    df.exphappy, # expected happiness with people you will meet\n",
    "    df.loc[:, 'attr3_1':'amb3_1'],  # self evaluation\n",
    "    df.loc[:, 'attr':'shar'],  # evaluation of partner\n",
    "    df.loc[:, 'attr1_1':'shar1_1'],  # what's important to you, sum to 100 \n",
    "    df.loc[:, 'pf_o_att':'pf_o_sha'], # what's important to partner, sum to 100\n",
    "], axis=1)\n",
    "\n",
    "y = pd.concat([\n",
    "    df.match,  # Label for two-way prediction, whether two people will be a good match\n",
    "    df.dec_o  # Label for one way prediction, whether your partner will say \"yes\"\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6988"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = X.dropna()\n",
    "len(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert y.match.count() == len(X.index)\n",
    "# assert y.dec_o.count() == len(X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy for match: 0.835086\n",
      "Baseline accuracy for decision: 0.525335\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline accuracy for match: %f\" % (1 - df.match.sum()/df.match.count()))\n",
    "print(\"Baseline accuracy for decision: %f\" % (1 - df.dec_o.sum()/df.dec_o.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['1_1total'] = df.loc[:, 'attr1_1':'shar1_1'].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pid (partner's unique ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[X.pid.isnull()]  # The missing pid comes from same person in one night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assign a new pid to the person missing\n",
    "# X.pid.fillna(X.pid.max() + 1, inplace=True)\n",
    "# assert X.pid.isna().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importance ratings: fill with 100/6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.loc[:, 'attr1_1':'pf_o_sha'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.attr1_1.fillna(100/6, inplace=True)\n",
    "# X.sinc1_1.fillna(100/6, inplace=True)\n",
    "# X.intel1_1.fillna(100/6, inplace=True)\n",
    "# X.fun1_1.fillna(100/6, inplace=True)\n",
    "# X.amb1_1.fillna(100/6, inplace=True)\n",
    "# X.shar1_1.fillna(100/6, inplace=True)\n",
    "# X.pf_o_att.fillna(100/6, inplace=True)\n",
    "# X.pf_o_sin.fillna(100/6, inplace=True)\n",
    "# X.pf_o_int.fillna(100/6, inplace=True)\n",
    "# X.pf_o_fun.fillna(100/6, inplace=True)\n",
    "# X.pf_o_amb.fillna(100/6, inplace=True)\n",
    "# X.pf_o_sha.fillna(100/6, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert X.loc[:, 'attr1_1':'pf_o_sha'].isna().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.date.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### goal: convert to indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(X.goal, \n",
    "                         prefix='goal', \n",
    "                         dummy_na=True, \n",
    "                         drop_first=False)\n",
    "\n",
    "X = X.drop('goal', axis=1)\n",
    "X = X.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "X.fillna(X.median(), inplace=True)\n",
    "y = y.drop(columns=['dec_o']).values.ravel()\n",
    "X, y = SMOTE().fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(columns=['iid', 'partner', 'pid'], inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=.2,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### age: fill with median among gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.age.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fill missing age values with median age among gender\n",
    "# X_train['age'] = X_train.groupby('gender').transform(lambda group: group.fillna(group.median()))\n",
    "# X_train['age_o'] = X_train.groupby('gender').transform(lambda group: group.fillna(group.median()))\n",
    "\n",
    "# X_test['age'] = X_test.groupby('gender').transform(lambda group: group.fillna(group.median()))\n",
    "# X_test['age_o'] = X_test.groupby('gender').transform(lambda group: group.fillna(group.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert X_train.age.isna().sum() == 0\n",
    "# assert X_train.age_o.isna().sum() == 0\n",
    "\n",
    "# assert X_test.age.isna().sum() == 0\n",
    "# assert X_test.age_o.isna().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### int_corr, date, exphappy, self evaluation: fill with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Programs\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "X_train.fillna(X_train.median(), inplace=True)\n",
    "X_test.fillna(X_test.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # imp = SimpleImputer(missing_values=np.nan, strategy='mean') # .40 best\n",
    "# # imp = IterativeImputer(max_iter=10) # .50 best\n",
    "# imp = SimpleImputer(missing_values=np.nan, strategy='median') #.44\n",
    "# X_train_i = pd.DataFrame(imp.fit_transform(X_train))\n",
    "# X_train_i.columns = X_train.columns\n",
    "# X_train_i.index = X_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "# # imp = IterativeImputer(max_iter=10)\n",
    "# imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "# X_test_i = pd.DataFrame(imp.fit_transform(X_test))\n",
    "# X_test_i.columns = X_test.columns\n",
    "# X_test_i.index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train.isna().sum().sum() == 0\n",
    "assert X_test.isna().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('data/X_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('data/X_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv('data/y_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv('data/y_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
